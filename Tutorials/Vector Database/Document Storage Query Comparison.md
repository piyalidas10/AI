# ğŸŸ¢ FULL FLOW: Document Storage + Query Comparison

> ğŸ“„ Document â†’ Vector â†’ Store in DB â†’ Query â†’ Compare â†’ Return Results

**Weâ€™ll divide into 2 parts:**

1ï¸âƒ£ Document Ingestion (Storing Phase)
2ï¸âƒ£ Query Search (Retrieval Phase)

## ğŸŸ¦ PART 1: Document â†’ Vector â†’ Store in Vector DB
**ğŸ”¹ Step 1: Raw Document**

Example document:
```
"FastAPI is a modern Python web framework."
```
This is plain text (unstructured data).

**ğŸ”¹ Step 2: Convert Text â†’ Embedding**

Using embedding model (for example from Ollama or OpenAI)

It converts text into a numeric vector:
```
[0.21, -0.84, 0.55, 0.10, 0.73, ...]
```

Think of this as:  
ğŸ‘‰ A coordinate in 768-dimensional space  
ğŸ‘‰ A compressed meaning of the sentence  

**ğŸ”¹ Step 3: Store in Vector Database**

Example vector database:
  -  Qdrant
  -  Pinecone
  -  Weaviate

The database stores:
```
{
  id: 101,
  vector: [0.21, -0.84, 0.55, 0.10, 0.73...],
  payload: {
      text: "FastAPI is a modern Python web framework",
      source: "blog1"
  }
}
```

Important:
  -  The actual searchable part = VECTOR
  -  The text is stored as metadata (payload)

**ğŸ”¹ Step 4: Index Creation (Very Important)**

The DB builds a special structure:

ğŸ‘‰ HNSW graph (not simple B-tree like SQL)

This makes nearest neighbor search very fast.

Now documents are ready to search.

## ğŸŸ¢ PART 2: Query â†’ Compare â†’ Return Top-K
ğŸ”¹ Step 5: User Sends Query

User asks:
```
"FastAPI tutorial"
```

**ğŸ”¹ Step 6: Query â†’ Embedding**

Same embedding model converts query into vector:
```
Query Vector (Q)
[0.20, -0.80, 0.50, 0.08, 0.70...]
```

âš  Important:  
Query must use SAME embedding model as documents.

**ğŸ”¹ Step 7: Similarity Comparison**

Now database compares:
```
Query Vector (Q)
vs
All Document Vectors
```

It calculates similarity score using:
  -  Cosine similarity (most common)
  -  Dot product
  -  Euclidean distance

In simple terms:  
ğŸ‘‰ Which vectors are closest to Q in multi-dimensional space?

**ğŸ”¹ Step 8: Ranking**

Example similarity scores:
```
Doc A â†’ 0.95
Doc B â†’ 0.92
Doc C â†’ 0.30
```

If K = 2

Return:
```
Doc A
Doc B
```

This is called:  
ğŸ¯ Top-K Retrieval

## ğŸ”¥ COMPLETE VISUAL FLOW

DOCUMENT INGESTION FLOW
-----------------------------------------------------------------
```
Raw Text
   â†“
Embedding Model
   â†“
Vector (Numbers)
   â†“
Store in Vector DB
   â†“
Build HNSW Index
```

QUERY SEARCH FLOW
-----------------------------------------------------------------
```
User Query
   â†“
Embedding Model
   â†“
Query Vector
   â†“
Vector DB
   â†“
Similarity Calculation
   â†“
Find Nearest Neighbors
   â†“
Return Top-K Results
```

## ğŸ§  What Actually Gets Compared?

NOT:
```
"FastAPI tutorial" == "FastAPI guide"
```

BUT:
```
[0.20, -0.80, 0.50...] 
compared with
[0.21, -0.84, 0.55...]
```
Pure numeric comparison.
